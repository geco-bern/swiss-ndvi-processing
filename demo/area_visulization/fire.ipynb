{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window cols 16879..17090 (212), rows 17602..17851 (250)\n",
      "Mask has 105715396 True pixels.\n",
      "Pixels in window: 53000, masked pixels: 26886\n"
     ]
    }
   ],
   "source": [
    "# find correct pixel\n",
    "import numpy as np\n",
    "import math\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import rioxarray\n",
    "import zarr\n",
    "import pandas as pd\n",
    "\n",
    "# ----- Config -----\n",
    "zarr_path = \"/data_2/scratch/sbiegel/processed/ndvi_dataset.zarr/ndvi\"\n",
    "mask_path = \"/data_2/scratch/sbiegel/processed/forest_mask.npy\"\n",
    "out_gif = \"ndvi_rect_first500.gif\"\n",
    "\n",
    "z = zarr.open(zarr_path)\n",
    "\n",
    "out_path = \"/data_2/scratch/sbiegel/processed/ndvi_dataset_gapfilled.zarr/ndvi\"\n",
    "z_out = zarr.open(\n",
    "    out_path,\n",
    "    mode=\"w\",\n",
    "    shape=z_in.shape,\n",
    "    chunks=z_in.chunks,    \n",
    "    dtype=z_in.dtype\n",
    ")\n",
    "\n",
    "\n",
    "# Raster info\n",
    "height, width = 24542, 37728\n",
    "left, bottom = 2474090.0, 1065110.0\n",
    "px = 10.0\n",
    "top = bottom + height * px\n",
    "\n",
    "# Rectangle corners (UL and BR)\n",
    "UL_x, UL_y = 2642881.029823, 1134500.699745\n",
    "BR_x, BR_y = 2644996.031941, 1132012.862203\n",
    "\n",
    "# ----- compute pixel window (row 0 = top) -----\n",
    "x_min, x_max = min(UL_x, BR_x), max(UL_x, BR_x)\n",
    "y_min, y_max = min(UL_y, BR_y), max(UL_y, BR_y)\n",
    "\n",
    "col_min = int(math.floor((x_min - left) / px))\n",
    "col_max = int(math.floor((x_max - left) / px))\n",
    "\n",
    "row_min = int(math.floor((top - y_max) / px))\n",
    "row_max = int(math.floor((top - y_min) / px))\n",
    "\n",
    "# clip to bounds\n",
    "col_min = max(0, min(width-1, col_min))\n",
    "col_max = max(0, min(width-1, col_max))\n",
    "row_min = max(0, min(height-1, row_min))\n",
    "row_max = max(0, min(height-1, row_max))\n",
    "\n",
    "win_cols = col_max - col_min + 1\n",
    "win_rows = row_max - row_min + 1\n",
    "print(f\"Window cols {col_min}..{col_max} ({win_cols}), rows {row_min}..{row_max} ({win_rows})\")\n",
    "\n",
    "# ----- load mask -----\n",
    "mask = np.load(mask_path)\n",
    "assert mask.shape == (height, width), f\"Mask shape {mask.shape} != raster {(height, width)}\"\n",
    "\n",
    "mask_flat = mask.ravel(order='C')\n",
    "masked_positions = np.flatnonzero(mask_flat)\n",
    "n_masked = masked_positions.size\n",
    "print(f\"Mask has {n_masked} True pixels.\")\n",
    "\n",
    "# build index map from full array -> masked array\n",
    "idx_map = np.full(mask_flat.shape[0], -1, dtype=np.int64)\n",
    "idx_map[masked_positions] = np.arange(n_masked, dtype=np.int64)\n",
    "\n",
    "# ----- compute flat indices in window -----\n",
    "rows = np.arange(row_min, row_max+1, dtype=np.int64)\n",
    "cols = np.arange(col_min, col_max+1, dtype=np.int64)\n",
    "rr, cc = np.meshgrid(rows, cols, indexing='ij')\n",
    "full_flat_idx = (rr * width + cc).ravel()\n",
    "\n",
    "masked_idx_in_window = idx_map[full_flat_idx]\n",
    "is_masked = masked_idx_in_window >= 0\n",
    "n_masked_in_window = is_masked.sum()\n",
    "print(f\"Pixels in window: {full_flat_idx.size}, masked pixels: {n_masked_in_window}\")\n",
    "\n",
    "if n_masked_in_window == 0:\n",
    "    raise RuntimeError(\"No masked pixels in window!\")\n",
    "\n",
    "# ----- open Zarr -----\n",
    "N, T = z.shape\n",
    "assert N == n_masked, f\"Zarr first-dim {N} != mask True count {n_masked}\"\n",
    "\n",
    "# ----- plotting extent -----\n",
    "extent = (\n",
    "    left + col_min * px,\n",
    "    left + (col_max + 1) * px,\n",
    "    top - (row_max + 1) * px,\n",
    "    top - row_min * px\n",
    ")\n",
    "\n",
    "\n",
    "values = np.empty(n_masked_in_window, dtype=float)\n",
    "batch = 1_000_000\n",
    "start = 0\n",
    "end = min(start + batch, n_masked_in_window)\n",
    "sel = masked_idx_in_window[is_masked][start:end].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5375587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_zarr(\"/home/francesco/data_scratch/swiss-ndvi-processing/sample_seasonal_cycle_parameter_preds.zarr\")\n",
    "ndvi = ds['ndvi']\n",
    "dates = ds['dates']\n",
    "\n",
    "params_lower = torch.tensor(ds[\"params_lower\"].values)\n",
    "params_upper = torch.tensor(ds[\"params_upper\"].values)\n",
    "\n",
    "# convert dates to doy\n",
    "dates_pd = pd.to_datetime(dates)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': dates_pd\n",
    "})\n",
    "\n",
    "# Sort by date\n",
    "df_sorted = df.sort_values(by='date')\n",
    "\n",
    "# Extract the sorted arrays if needed\n",
    "dates_sorted = df_sorted['date'].values\n",
    "dates_pd_sorted = pd.to_datetime(dates_sorted)\n",
    "\n",
    "doy = dates_pd_sorted.dayofyear.values\n",
    "\n",
    "doy = torch.tensor(doy, dtype=torch.float32)\n",
    "T_SCALE = 1.0 / 365.0\n",
    "t = doy.unsqueeze(0).repeat(params_lower.shape[0], 1) * T_SCALE\n",
    "\n",
    "# Define the double logistic function\n",
    "def double_logistic_function(t, params):\n",
    "    sos, mat_minus_sos, sen, eos_minus_sen, M, m = torch.split(params, 1, dim=1)\n",
    "    mat_minus_sos = torch.nn.functional.softplus(mat_minus_sos)\n",
    "    eos_minus_sen = torch.nn.functional.softplus(eos_minus_sen)\n",
    "    sigmoid_sos_mat = torch.nn.functional.sigmoid(\n",
    "        -2 * (2 * sos + mat_minus_sos - 2 * t) / (mat_minus_sos + 1e-10)\n",
    "    )\n",
    "    sigmoid_sen_eos = torch.nn.functional.sigmoid(\n",
    "        -2 * (2 * sen + eos_minus_sen - 2 * t) / (eos_minus_sen + 1e-10)\n",
    "    )\n",
    "    return (M - m) * (sigmoid_sos_mat - sigmoid_sen_eos) + m\n",
    "\n",
    "lower = double_logistic_function(t[[0]], params_lower[[91]]).squeeze().cpu().numpy()\n",
    "upper = double_logistic_function(t[[0]], params_upper[[91]]).squeeze().cpu().numpy()\n",
    "\n",
    "iqr = lower -upper\n",
    "\n",
    "median_iqr = upper - iqr/2\n",
    "\n",
    "param_iqr =1.5\n",
    "bottom_iqr = 0.3\n",
    "upper_iqr = 0.7\n",
    "\n",
    "dates_pd = pd.to_datetime(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5559da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:1400: RuntimeWarning: invalid value encountered in cast\n",
      "  value = value.astype(dtype=self.metadata.dtype, order=\"A\")\n"
     ]
    }
   ],
   "source": [
    "for pixel in sel[0:100]:\n",
    "\n",
    "    time_serie = z[pixel, ].astype(float)\n",
    "    time_serie /= 10000.0\n",
    "\n",
    "    # mask clouds\n",
    "    time_serie = np.where((time_serie > 1) | (time_serie < 0), np.nan, time_serie)\n",
    "\n",
    "    z[pixel, ] = time_serie\n",
    "\n",
    "\n",
    "    # proper sorting\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates_pd,\n",
    "        'ndvi': time_serie\n",
    "        })\n",
    "\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    dates_sorted = df_sorted['date'].values\n",
    "    ndvi_sorted = df_sorted['ndvi'].values\n",
    "\n",
    "    # initialize ndvi gapfilled\n",
    "    ndvi_gapfilled = np.copy(ndvi_sorted)\n",
    "\n",
    "\n",
    "    valid_idx = np.where(np.isfinite(ndvi_sorted))\n",
    "    valid_ndvi = ndvi_sorted[valid_idx]\n",
    "    valid_idx = np.array(valid_idx[0])\n",
    "    valid_upper = upper[valid_idx]\n",
    "    valid_lower = lower[valid_idx]\n",
    "\n",
    "    valid_iqr = valid_upper - valid_lower\n",
    "\n",
    "    median_valid = valid_upper - valid_iqr / 2\n",
    "\n",
    "    # initialize outlier flag\n",
    "    outlier_arr = np.repeat(False,len(dates))\n",
    "\n",
    "    #######################\n",
    "    ## outlier detection ##\n",
    "    #######################\n",
    "\n",
    "    # calculate threshold\n",
    "    delta_threshold_upper = valid_upper + param_iqr * valid_iqr\n",
    "    delta_threshold_lower = valid_lower - param_iqr * valid_iqr\n",
    "\n",
    "    # outlier detection by threshold\n",
    "\n",
    "    deltas = []\n",
    "    is_outlier_threshold = []\n",
    "\n",
    "    for i in range(0,len(valid_idx)):\n",
    "\n",
    "        if valid_ndvi[i] > valid_upper[i]:\n",
    "\n",
    "                delta = valid_ndvi[i] - valid_upper[i]\n",
    "\n",
    "                if valid_ndvi[i] > delta_threshold_upper[i]:\n",
    "                    \n",
    "                    outlier = True\n",
    "                else:\n",
    "                    outlier = False\n",
    "        \n",
    "        elif (valid_ndvi[i] < valid_upper[i]) and (valid_ndvi[i] > valid_lower[i]):\n",
    "            \n",
    "            delta = valid_ndvi[i] - (valid_upper[i] - valid_iqr[i])\n",
    "            outlier = False\n",
    "\n",
    "        else:\n",
    "                delta = valid_ndvi[i] - valid_lower[i]\n",
    "\n",
    "                if valid_ndvi[i] < delta_threshold_lower[i]:\n",
    "                    \n",
    "                    outlier = True\n",
    "                else:\n",
    "                    outlier = False\n",
    "\n",
    "        deltas.append(delta)\n",
    "        is_outlier_threshold.append(outlier)\n",
    "        \n",
    "    is_outlier_threshold = np.array(is_outlier_threshold)\n",
    "    deltas = np.array(deltas)\n",
    "\n",
    "    # outlier detection by deltas neighbour\n",
    "    # the deltas are calculated based on the neaster bound\n",
    "\n",
    "    delta_delta_left = (deltas[1:] - deltas[:-1]) \n",
    "    delta_delta_right = (deltas[:-1] - deltas[1:]) \n",
    "\n",
    "    delta_delta_left = np.array(delta_delta_left)\n",
    "    delta_delta_right = np.array(delta_delta_right)\n",
    "\n",
    "\n",
    "    slope_is_outlier = np.logical_and(\n",
    "            \n",
    "            np.logical_or(delta_delta_left[1:] > np.quantile(delta_delta_left,upper_iqr), \n",
    "                        delta_delta_left[1:]  <  np.quantile(delta_delta_left,bottom_iqr)),\n",
    "\n",
    "            np.logical_or(delta_delta_right[:-1]  > np.quantile(delta_delta_right,upper_iqr), \n",
    "                        delta_delta_right[:-1]  < np.quantile(delta_delta_right,bottom_iqr))\n",
    "        )\n",
    "\n",
    "\n",
    "    # to be an outlier, a point must met both conditions\n",
    "    is_outlier = np.logical_and(is_outlier_threshold[1:-1],slope_is_outlier)\n",
    "\n",
    "    # write the outlier in the new data\n",
    "    outlier_arr[valid_idx[1:-1]] = is_outlier\n",
    "\n",
    "    # outlier detection first and last\n",
    "    if np.logical_and(\n",
    "        \n",
    "        np.logical_or(\n",
    "            delta_delta_right[0] >= np.quantile(delta_delta_right,upper_iqr), \n",
    "            delta_delta_right[0] <= np.quantile(delta_delta_right,bottom_iqr)\n",
    "            ),\n",
    "            \n",
    "            is_outlier_threshold[0]):\n",
    "\n",
    "        outlier_arr[valid_idx[0]] = True\n",
    "        ndvi_gapfilled[valid_idx[0]] = np.nan\n",
    "\n",
    "    if np.logical_and(\n",
    "                    \n",
    "            np.logical_or(\n",
    "                delta_delta_left[-1] >= np.quantile(delta_delta_left,upper_iqr), \n",
    "                delta_delta_left[-1] <= np.quantile(delta_delta_left,bottom_iqr)\n",
    "                ),\n",
    "                \n",
    "                is_outlier_threshold[-1]) == True:\n",
    "\n",
    "\n",
    "        outlier_arr[valid_idx[-1]] = True\n",
    "        ndvi_gapfilled[valid_idx[-1]] = np.nan\n",
    "\n",
    "    #######################\n",
    "    ## linear gapfilling ##\n",
    "    #######################\n",
    "\n",
    "    to_remove = valid_idx[1:-1][is_outlier == True]\n",
    "    ndvi_gapfilled[to_remove] = np.nan\n",
    "\n",
    "    valid_idx = np.where(np.isfinite(ndvi_gapfilled))\n",
    "    valid_idx = np.array(valid_idx[0])\n",
    "\n",
    "    distances = valid_idx[1:] - valid_idx[:-1]  \n",
    "\n",
    "    for i in range(0,len(valid_idx)-1):\n",
    "\n",
    "        idx_to_gapfill = range(valid_idx[i]+1,valid_idx[i+1])\n",
    "        idx_to_gapfill = np.array(idx_to_gapfill)\n",
    "\n",
    "        if len(idx_to_gapfill) != 0: # if len == 0 means 2 contigous obs data\n",
    "\n",
    "            multiplier = range(1,len(idx_to_gapfill)+1)\n",
    "            multiplier = np.array(multiplier)\n",
    "\n",
    "            # gapfill based on the median\n",
    "\n",
    "            delta_1 = ndvi_gapfilled[valid_idx[i]] - median_iqr[valid_idx[i]] \n",
    "            delta_2 = ndvi_gapfilled[valid_idx[i+1]] - median_iqr[valid_idx[i+1]] \n",
    "            \n",
    "            slope = (delta_2 - delta_1) / distances[i]\n",
    "\n",
    "            values = (median_iqr[idx_to_gapfill] + delta_1 + slope * multiplier ) \n",
    "\n",
    "\n",
    "            ndvi_gapfilled[idx_to_gapfill] = values\n",
    "\n",
    "\n",
    "    z_out[pixel, ] = ndvi_gapfilled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0baabb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GIF: ndvi_rect_first500.gif\n"
     ]
    }
   ],
   "source": [
    "n_frames = min(100, T)\n",
    "\n",
    "# ----- create GIF -----\n",
    "frames = []\n",
    "\n",
    "for t in np.arange(0,n_frames):\n",
    "    # read NDVI for masked pixels in window\n",
    "    values = np.empty(n_masked_in_window, dtype=float)\n",
    "    batch = 1_000_000\n",
    "\n",
    "    values_batch = z[sel, t].astype(float)\n",
    "\n",
    "    # reconstruct 2D window\n",
    "    window_arr = np.full(win_rows * win_cols, np.nan, dtype=float)\n",
    "    window_arr[is_masked] = values\n",
    "    window_arr = window_arr.reshape((win_rows, win_cols))\n",
    "\n",
    "    # plot frame\n",
    "    fig, ax = plt.subplots(figsize=(6, 6 * win_rows / win_cols))\n",
    "    im = ax.imshow(window_arr, origin='upper', extent=extent, vmin=0, vmax=1, cmap=\"RdYlGn\")\n",
    "    ax.set_title(f\"NDVI timestep {t}\")\n",
    "    ax.set_xlabel(\"EPSG:2056 (m)\")\n",
    "    ax.set_ylabel(\"EPSG:2056 (m)\")\n",
    "    plt.colorbar(im, ax=ax, label=\"NDVI\")\n",
    "\n",
    "    # convert to image\n",
    "    fig.canvas.draw()\n",
    "    buf = np.asarray(fig.canvas.buffer_rgba())\n",
    "    image = buf[:, :, :3].copy()\n",
    "    frames.append(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "# save GIF\n",
    "imageio.mimsave(out_gif, frames, fps=10)\n",
    "print(\"Saved GIF:\", out_gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca1103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UL (EPSG:4326): 7.9958091403159965 46.36051916009676\n",
      "BR (EPSG:4326): 8.023048457332893 46.33800179890188\n",
      "Bounding box: [7.9958091403159965, 46.33800179890188, 8.023048457332893, 46.36051916009676]\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "# Define transformer from EPSG:2056 → EPSG:4326\n",
    "transformer = Transformer.from_crs(\"EPSG:2056\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Your coordinates (upper-left and bottom-right in EPSG:2056)\n",
    "UL_x, UL_y = 2642881.029823, 1134500.699745\n",
    "BR_x, BR_y = 2644996.031941, 1132012.862203\n",
    "\n",
    "# Transform to WGS84\n",
    "UL_lon, UL_lat = transformer.transform(UL_x, UL_y)\n",
    "BR_lon, BR_lat = transformer.transform(BR_x, BR_y)\n",
    "\n",
    "# Construct bbox in [min_lon, min_lat, max_lon, max_lat]\n",
    "bbox_4326 = [min(UL_lon, BR_lon), min(UL_lat, BR_lat),\n",
    "             max(UL_lon, BR_lon), max(UL_lat, BR_lat)]\n",
    "\n",
    "print(\"UL (EPSG:4326):\", UL_lon, UL_lat)\n",
    "print(\"BR (EPSG:4326):\", BR_lon, BR_lat)\n",
    "print(\"Bounding box:\", bbox_4326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dd243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(4%2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndvi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
