{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e6a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window cols 21291..21391 (101), rows 6453..6553 (101)\n",
      "Mask has 105715396 True pixels.\n",
      "Pixels in window: 10201, masked pixels: 2172\n"
     ]
    }
   ],
   "source": [
    "# find correct pixel\n",
    "import numpy as np\n",
    "import math\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import rioxarray\n",
    "import zarr\n",
    "import pandas as pd\n",
    "\n",
    "# ----- Config -----\n",
    "zarr_path = \"/data_2/scratch/sbiegel/processed/ndvi_dataset.zarr/ndvi\"\n",
    "mask_path = \"/data_2/scratch/sbiegel/processed/forest_mask.npy\"\n",
    "out_gif = \"ndvi_lowland_broadleaf_non_gapfilled.gif\"\n",
    "\n",
    "z = zarr.open(zarr_path, mode = \"r\")\n",
    "\n",
    "\n",
    "# Raster info\n",
    "height, width = 24542, 37728\n",
    "left, bottom = 2474090.0, 1065110.0\n",
    "px = 10.0\n",
    "top = bottom + height * px\n",
    "\n",
    "# Rectangle corners (UL and BR)\n",
    "UL_x, UL_y = 2687000.000000, 1246000.000000\n",
    "BR_x, BR_y = 2688000.000000, 1245000.000000\n",
    "\n",
    "# ----- compute pixel window (row 0 = top) -----\n",
    "x_min, x_max = min(UL_x, BR_x), max(UL_x, BR_x)\n",
    "y_min, y_max = min(UL_y, BR_y), max(UL_y, BR_y)\n",
    "\n",
    "col_min = int(math.floor((x_min - left) / px))\n",
    "col_max = int(math.floor((x_max - left) / px))\n",
    "\n",
    "row_min = int(math.floor((top - y_max) / px))\n",
    "row_max = int(math.floor((top - y_min) / px))\n",
    "\n",
    "# clip to bounds\n",
    "col_min = max(0, min(width-1, col_min))\n",
    "col_max = max(0, min(width-1, col_max))\n",
    "row_min = max(0, min(height-1, row_min))\n",
    "row_max = max(0, min(height-1, row_max))\n",
    "\n",
    "win_cols = col_max - col_min + 1\n",
    "win_rows = row_max - row_min + 1\n",
    "print(f\"Window cols {col_min}..{col_max} ({win_cols}), rows {row_min}..{row_max} ({win_rows})\")\n",
    "\n",
    "# ----- load mask -----\n",
    "mask = np.load(mask_path)\n",
    "assert mask.shape == (height, width), f\"Mask shape {mask.shape} != raster {(height, width)}\"\n",
    "\n",
    "mask_flat = mask.ravel(order='C')\n",
    "masked_positions = np.flatnonzero(mask_flat)\n",
    "n_masked = masked_positions.size\n",
    "print(f\"Mask has {n_masked} True pixels.\")\n",
    "\n",
    "# build index map from full array -> masked array\n",
    "idx_map = np.full(mask_flat.shape[0], -1, dtype=np.int64)\n",
    "idx_map[masked_positions] = np.arange(n_masked, dtype=np.int64)\n",
    "\n",
    "# ----- compute flat indices in window -----\n",
    "rows = np.arange(row_min, row_max+1, dtype=np.int64)\n",
    "cols = np.arange(col_min, col_max+1, dtype=np.int64)\n",
    "rr, cc = np.meshgrid(rows, cols, indexing='ij')\n",
    "full_flat_idx = (rr * width + cc).ravel()\n",
    "\n",
    "masked_idx_in_window = idx_map[full_flat_idx]\n",
    "is_masked = masked_idx_in_window >= 0\n",
    "n_masked_in_window = is_masked.sum()\n",
    "print(f\"Pixels in window: {full_flat_idx.size}, masked pixels: {n_masked_in_window}\")\n",
    "\n",
    "if n_masked_in_window == 0:\n",
    "    raise RuntimeError(\"No masked pixels in window!\")\n",
    "\n",
    "# ----- open Zarr -----\n",
    "N, T = z.shape\n",
    "assert N == n_masked, f\"Zarr first-dim {N} != mask True count {n_masked}\"\n",
    "\n",
    "# ----- plotting extent -----\n",
    "extent = (\n",
    "    left + col_min * px,\n",
    "    left + (col_max + 1) * px,\n",
    "    top - (row_max + 1) * px,\n",
    "    top - row_min * px\n",
    ")\n",
    "\n",
    "\n",
    "values = np.empty(n_masked_in_window, dtype=float)\n",
    "batch = 1_000_000\n",
    "start = 0\n",
    "end = min(start + batch, n_masked_in_window)\n",
    "sel = masked_idx_in_window[is_masked][start:end].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbdb522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GIF: ndvi_lowland_broadleaf.gif\n"
     ]
    }
   ],
   "source": [
    "# Limit to first 500 timesteps or all\n",
    "n_frames = min(100, T)\n",
    "\n",
    "# ----- plotting extent -----\n",
    "extent = (\n",
    "    left + col_min * px,\n",
    "    left + (col_max + 1) * px,\n",
    "    top - (row_max + 1) * px,\n",
    "    top - row_min * px\n",
    ")\n",
    "\n",
    "# ----- create GIF -----\n",
    "frames = []\n",
    "\n",
    "for t in np.arange(0,n_frames):\n",
    "    # read NDVI for masked pixels in window\n",
    "    values = np.empty(n_masked_in_window, dtype=float)\n",
    "    batch = 1_000_000\n",
    "    start = 0\n",
    "    while start < n_masked_in_window:\n",
    "        end = min(start + batch, n_masked_in_window)\n",
    "        sel = masked_idx_in_window[is_masked][start:end].tolist()\n",
    "        values_batch = z[sel, t].astype(float)\n",
    "\n",
    "        # normalize\n",
    "        values_batch /= 10000.0\n",
    "\n",
    "        # mask clouds\n",
    "        values_batch = np.where((values_batch > 1) | (values_batch < 0), np.nan, values_batch)\n",
    "\n",
    "        values[start:end] = values_batch\n",
    "        start = end\n",
    "\n",
    "    # reconstruct 2D window\n",
    "    window_arr = np.full(win_rows * win_cols, np.nan, dtype=float)\n",
    "    window_arr[is_masked] = values\n",
    "    window_arr = window_arr.reshape((win_rows, win_cols))\n",
    "\n",
    "    # plot frame\n",
    "    fig, ax = plt.subplots(figsize=(6, 6 * win_rows / win_cols))\n",
    "    im = ax.imshow(window_arr, origin='upper', extent=extent, vmin=0, vmax=1, cmap=\"RdYlGn\")\n",
    "    ax.set_title(f\"NDVI timestep {t}\")\n",
    "    ax.set_xlabel(\"EPSG:2056 (m)\")\n",
    "    ax.set_ylabel(\"EPSG:2056 (m)\")\n",
    "    plt.colorbar(im, ax=ax, label=\"NDVI\")\n",
    "\n",
    "    # convert to image\n",
    "    fig.canvas.draw()\n",
    "    buf = np.asarray(fig.canvas.buffer_rgba())\n",
    "    image = buf[:, :, :3].copy()\n",
    "    frames.append(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "# save GIF\n",
    "imageio.mimsave(out_gif, frames, fps=10)\n",
    "print(\"Saved GIF:\", out_gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672d2bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_zarr(\"/home/francesco/data_scratch/swiss-ndvi-processing/sample_seasonal_cycle_parameter_preds.zarr\")\n",
    "ndvi = ds['ndvi']\n",
    "dates = ds['dates']\n",
    "\n",
    "params_lower = torch.tensor(ds[\"params_lower\"].values)\n",
    "params_upper = torch.tensor(ds[\"params_upper\"].values)\n",
    "\n",
    "# convert dates to doy\n",
    "dates_pd = pd.to_datetime(dates)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': dates_pd\n",
    "})\n",
    "\n",
    "# Sort by date\n",
    "df_sorted = df.sort_values(by='date')\n",
    "\n",
    "# Extract the sorted arrays if needed\n",
    "dates_sorted = df_sorted['date'].values\n",
    "dates_pd_sorted = pd.to_datetime(dates_sorted)\n",
    "\n",
    "doy = dates_pd_sorted.dayofyear.values\n",
    "\n",
    "doy = torch.tensor(doy, dtype=torch.float32)\n",
    "T_SCALE = 1.0 / 365.0\n",
    "t = doy.unsqueeze(0).repeat(params_lower.shape[0], 1) * T_SCALE\n",
    "\n",
    "# Define the double logistic function\n",
    "def double_logistic_function(t, params):\n",
    "    sos, mat_minus_sos, sen, eos_minus_sen, M, m = torch.split(params, 1, dim=1)\n",
    "    mat_minus_sos = torch.nn.functional.softplus(mat_minus_sos)\n",
    "    eos_minus_sen = torch.nn.functional.softplus(eos_minus_sen)\n",
    "    sigmoid_sos_mat = torch.nn.functional.sigmoid(\n",
    "        -2 * (2 * sos + mat_minus_sos - 2 * t) / (mat_minus_sos + 1e-10)\n",
    "    )\n",
    "    sigmoid_sen_eos = torch.nn.functional.sigmoid(\n",
    "        -2 * (2 * sen + eos_minus_sen - 2 * t) / (eos_minus_sen + 1e-10)\n",
    "    )\n",
    "    return (M - m) * (sigmoid_sos_mat - sigmoid_sen_eos) + m\n",
    "\n",
    "lower = double_logistic_function(t[[0]], params_lower[[91]]).squeeze().cpu().numpy()\n",
    "upper = double_logistic_function(t[[0]], params_upper[[91]]).squeeze().cpu().numpy()\n",
    "\n",
    "iqr = lower -upper\n",
    "\n",
    "median_iqr = upper - iqr/2\n",
    "\n",
    "param_iqr =1.5\n",
    "bottom_iqr = 0.3\n",
    "upper_iqr = 0.7\n",
    "\n",
    "dates_pd = pd.to_datetime(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8deaf8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:1400: RuntimeWarning: invalid value encountered in cast\n",
      "  value = value.astype(dtype=self.metadata.dtype, order=\"A\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "error during blosc decompression: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    168\u001b[39m         values = (median_iqr[idx_to_gapfill] + delta_1 + slope * multiplier ) \n\u001b[32m    171\u001b[39m         ndvi_gapfilled[idx_to_gapfill] = values\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m z_out[:, pixel] = ndvi_gapfilled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:2526\u001b[39m, in \u001b[36mArray.__setitem__\u001b[39m\u001b[34m(self, selection, value)\u001b[39m\n\u001b[32m   2524\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_orthogonal_selection(pure_selection, value, fields=fields)\n\u001b[32m   2525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2526\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_basic_selection(cast(BasicSelection, pure_selection), value, fields=fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/_compat.py:43\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     46\u001b[39m args_msg = [\n\u001b[32m     47\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:], strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     49\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:2746\u001b[39m, in \u001b[36mArray.set_basic_selection\u001b[39m\u001b[34m(self, selection, value, fields, prototype)\u001b[39m\n\u001b[32m   2744\u001b[39m     prototype = default_buffer_prototype()\n\u001b[32m   2745\u001b[39m indexer = BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m.shape, \u001b[38;5;28mself\u001b[39m.metadata.chunk_grid)\n\u001b[32m-> \u001b[39m\u001b[32m2746\u001b[39m sync(\u001b[38;5;28mself\u001b[39m._async_array._set_selection(indexer, value, fields=fields, prototype=prototype))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/sync.py:163\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(coro, loop, timeout)\u001b[39m\n\u001b[32m    160\u001b[39m return_result = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(finished)).result()\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/sync.py:119\u001b[39m, in \u001b[36m_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[33;03mexception, the exception will be returned.\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:1415\u001b[39m, in \u001b[36mAsyncArray._set_selection\u001b[39m\u001b[34m(self, indexer, value, prototype, fields)\u001b[39m\n\u001b[32m   1412\u001b[39m     _config = replace(_config, order=\u001b[38;5;28mself\u001b[39m.metadata.order)\n\u001b[32m   1414\u001b[39m \u001b[38;5;66;03m# merging with existing data and encoding chunks\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1415\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.codec_pipeline.write(\n\u001b[32m   1416\u001b[39m     [\n\u001b[32m   1417\u001b[39m         (\n\u001b[32m   1418\u001b[39m             \u001b[38;5;28mself\u001b[39m.store_path / \u001b[38;5;28mself\u001b[39m.metadata.encode_chunk_key(chunk_coords),\n\u001b[32m   1419\u001b[39m             \u001b[38;5;28mself\u001b[39m.metadata.get_chunk_spec(chunk_coords, _config, prototype),\n\u001b[32m   1420\u001b[39m             chunk_selection,\n\u001b[32m   1421\u001b[39m             out_selection,\n\u001b[32m   1422\u001b[39m             is_complete_chunk,\n\u001b[32m   1423\u001b[39m         )\n\u001b[32m   1424\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk_coords, chunk_selection, out_selection, is_complete_chunk \u001b[38;5;129;01min\u001b[39;00m indexer\n\u001b[32m   1425\u001b[39m     ],\n\u001b[32m   1426\u001b[39m     value_buffer,\n\u001b[32m   1427\u001b[39m     drop_axes=indexer.drop_axes,\n\u001b[32m   1428\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/codec_pipeline.py:479\u001b[39m, in \u001b[36mBatchedCodecPipeline.write\u001b[39m\u001b[34m(self, batch_info, value, drop_axes)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(\n\u001b[32m    474\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    475\u001b[39m     batch_info: Iterable[\u001b[38;5;28mtuple\u001b[39m[ByteSetter, ArraySpec, SelectorTuple, SelectorTuple, \u001b[38;5;28mbool\u001b[39m]],\n\u001b[32m    476\u001b[39m     value: NDBuffer,\n\u001b[32m    477\u001b[39m     drop_axes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, ...] = (),\n\u001b[32m    478\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m concurrent_map(\n\u001b[32m    480\u001b[39m         [\n\u001b[32m    481\u001b[39m             (single_batch_info, value, drop_axes)\n\u001b[32m    482\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m single_batch_info \u001b[38;5;129;01min\u001b[39;00m batched(batch_info, \u001b[38;5;28mself\u001b[39m.batch_size)\n\u001b[32m    483\u001b[39m         ],\n\u001b[32m    484\u001b[39m         \u001b[38;5;28mself\u001b[39m.write_batch,\n\u001b[32m    485\u001b[39m         config.get(\u001b[33m\"\u001b[39m\u001b[33masync.concurrency\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    486\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/common.py:68\u001b[39m, in \u001b[36mconcurrent_map\u001b[39m\u001b[34m(items, func, limit)\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[32m     66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*item)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[asyncio.ensure_future(run(item)) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/common.py:66\u001b[39m, in \u001b[36mconcurrent_map.<locals>.run\u001b[39m\u001b[34m(item)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(item: \u001b[38;5;28mtuple\u001b[39m[Any]) -> V:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/codec_pipeline.py:373\u001b[39m, in \u001b[36mBatchedCodecPipeline.write_batch\u001b[39m\u001b[34m(self, batch_info, value, drop_axes)\u001b[39m\n\u001b[32m    361\u001b[39m chunk_bytes_batch: Iterable[Buffer | \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    362\u001b[39m chunk_bytes_batch = \u001b[38;5;28;01mawait\u001b[39;00m concurrent_map(\n\u001b[32m    363\u001b[39m     [\n\u001b[32m    364\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m     config.get(\u001b[33m\"\u001b[39m\u001b[33masync.concurrency\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    372\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m chunk_array_decoded = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.decode_batch(\n\u001b[32m    374\u001b[39m     [\n\u001b[32m    375\u001b[39m         (chunk_bytes, chunk_spec)\n\u001b[32m    376\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk_bytes, (_, chunk_spec, *_) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    377\u001b[39m             chunk_bytes_batch, batch_info, strict=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    378\u001b[39m         )\n\u001b[32m    379\u001b[39m     ],\n\u001b[32m    380\u001b[39m )\n\u001b[32m    382\u001b[39m chunk_array_merged = [\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m._merge_chunk_array(\n\u001b[32m    384\u001b[39m         chunk_array,\n\u001b[32m   (...)\u001b[39m\u001b[32m    398\u001b[39m     ) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunk_array_decoded, batch_info, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    399\u001b[39m ]\n\u001b[32m    400\u001b[39m chunk_array_batch: \u001b[38;5;28mlist\u001b[39m[NDBuffer | \u001b[38;5;28;01mNone\u001b[39;00m] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/codec_pipeline.py:185\u001b[39m, in \u001b[36mBatchedCodecPipeline.decode_batch\u001b[39m\u001b[34m(self, chunk_bytes_and_specs)\u001b[39m\n\u001b[32m    178\u001b[39m (\n\u001b[32m    179\u001b[39m     aa_codecs_with_spec,\n\u001b[32m    180\u001b[39m     ab_codec_with_spec,\n\u001b[32m    181\u001b[39m     bb_codecs_with_spec,\n\u001b[32m    182\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._codecs_with_resolved_metadata_batched(chunk_specs)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bb_codec, chunk_spec_batch \u001b[38;5;129;01min\u001b[39;00m bb_codecs_with_spec[::-\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     chunk_bytes_batch = \u001b[38;5;28;01mawait\u001b[39;00m bb_codec.decode(\n\u001b[32m    186\u001b[39m         \u001b[38;5;28mzip\u001b[39m(chunk_bytes_batch, chunk_spec_batch, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    187\u001b[39m     )\n\u001b[32m    189\u001b[39m ab_codec, chunk_spec_batch = ab_codec_with_spec\n\u001b[32m    190\u001b[39m chunk_array_batch = \u001b[38;5;28;01mawait\u001b[39;00m ab_codec.decode(\n\u001b[32m    191\u001b[39m     \u001b[38;5;28mzip\u001b[39m(chunk_bytes_batch, chunk_spec_batch, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    192\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/abc/codec.py:129\u001b[39m, in \u001b[36mBaseCodec.decode\u001b[39m\u001b[34m(self, chunks_and_specs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    115\u001b[39m     chunks_and_specs: Iterable[\u001b[38;5;28mtuple\u001b[39m[CodecOutput | \u001b[38;5;28;01mNone\u001b[39;00m, ArraySpec]],\n\u001b[32m    116\u001b[39m ) -> Iterable[CodecInput | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    117\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decodes a batch of chunks.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    Chunks can be None in which case they are ignored by the codec.\u001b[39;00m\n\u001b[32m    119\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m \u001b[33;03m    Iterable[CodecInput | None]\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _batching_helper(\u001b[38;5;28mself\u001b[39m._decode_single, chunks_and_specs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/abc/codec.py:407\u001b[39m, in \u001b[36m_batching_helper\u001b[39m\u001b[34m(func, batch_info)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_batching_helper\u001b[39m(\n\u001b[32m    404\u001b[39m     func: Callable[[CodecInput, ArraySpec], Awaitable[CodecOutput | \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[32m    405\u001b[39m     batch_info: Iterable[\u001b[38;5;28mtuple\u001b[39m[CodecInput | \u001b[38;5;28;01mNone\u001b[39;00m, ArraySpec]],\n\u001b[32m    406\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[CodecOutput | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m concurrent_map(\n\u001b[32m    408\u001b[39m         \u001b[38;5;28mlist\u001b[39m(batch_info),\n\u001b[32m    409\u001b[39m         _noop_for_none(func),\n\u001b[32m    410\u001b[39m         config.get(\u001b[33m\"\u001b[39m\u001b[33masync.concurrency\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    411\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/common.py:68\u001b[39m, in \u001b[36mconcurrent_map\u001b[39m\u001b[34m(items, func, limit)\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[32m     66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*item)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[asyncio.ensure_future(run(item)) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/common.py:66\u001b[39m, in \u001b[36mconcurrent_map.<locals>.run\u001b[39m\u001b[34m(item)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(item: \u001b[38;5;28mtuple\u001b[39m[Any]) -> V:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m sem:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/abc/codec.py:420\u001b[39m, in \u001b[36m_noop_for_none.<locals>.wrap\u001b[39m\u001b[34m(chunk, chunk_spec)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(chunk, chunk_spec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/codecs/blosc.py:173\u001b[39m, in \u001b[36mBloscCodec._decode_single\u001b[39m\u001b[34m(self, chunk_bytes, chunk_spec)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decode_single\u001b[39m(\n\u001b[32m    169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    170\u001b[39m     chunk_bytes: Buffer,\n\u001b[32m    171\u001b[39m     chunk_spec: ArraySpec,\n\u001b[32m    172\u001b[39m ) -> Buffer:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\n\u001b[32m    174\u001b[39m         as_numpy_array_wrapper, \u001b[38;5;28mself\u001b[39m._blosc_codec.decode, chunk_bytes, chunk_spec.prototype\n\u001b[32m    175\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.fn(*\u001b[38;5;28mself\u001b[39m.args, **\u001b[38;5;28mself\u001b[39m.kwargs)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/buffer/cpu.py:213\u001b[39m, in \u001b[36mas_numpy_array_wrapper\u001b[39m\u001b[34m(func, buf, prototype)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mas_numpy_array_wrapper\u001b[39m(\n\u001b[32m    189\u001b[39m     func: Callable[[npt.NDArray[Any]], \u001b[38;5;28mbytes\u001b[39m], buf: core.Buffer, prototype: core.BufferPrototype\n\u001b[32m    190\u001b[39m ) -> core.Buffer:\n\u001b[32m    191\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Converts the input of `func` to a numpy array and the output back to `Buffer`.\u001b[39;00m\n\u001b[32m    192\u001b[39m \n\u001b[32m    193\u001b[39m \u001b[33;03m    This function is useful when calling a `func` that only support host memory such\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m \u001b[33;03m        The result of `func` converted to a `Buffer`\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prototype.buffer.from_bytes(func(buf.as_numpy_array()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumcodecs/blosc.pyx:573\u001b[39m, in \u001b[36mnumcodecs.blosc.Blosc.decode\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumcodecs/blosc.pyx:403\u001b[39m, in \u001b[36mnumcodecs.blosc.decompress\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: error during blosc decompression: 0"
     ]
    }
   ],
   "source": [
    "z_out =  zarr.open(\"/home/francesco/data_scratch/swiss-ndvi-processing/lowland_broadleaf.zarr/ndvi\")\n",
    "\n",
    "for pixel in np.arange(0,len(sel)-1):\n",
    "\n",
    "    pixel_sel = sel[pixel]\n",
    "\n",
    "    time_serie = z[pixel_sel, ].astype(float)\n",
    "    time_serie /= 10000.0\n",
    "\n",
    "    # mask clouds\n",
    "    time_serie = np.where((time_serie > 1) | (time_serie < 0), np.nan, time_serie)\n",
    "\n",
    "    # proper sorting\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates_pd,\n",
    "        'ndvi': time_serie\n",
    "        })\n",
    "\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    dates_sorted = df_sorted['date'].values\n",
    "    ndvi_sorted = df_sorted['ndvi'].values\n",
    "\n",
    "    # initialize ndvi gapfilled\n",
    "    ndvi_gapfilled = np.copy(ndvi_sorted)\n",
    "\n",
    "\n",
    "    valid_idx = np.where(np.isfinite(ndvi_sorted))\n",
    "    valid_ndvi = ndvi_sorted[valid_idx]\n",
    "    valid_idx = np.array(valid_idx[0])\n",
    "    valid_upper = upper[valid_idx]\n",
    "    valid_lower = lower[valid_idx]\n",
    "\n",
    "    valid_iqr = valid_upper - valid_lower\n",
    "\n",
    "    median_valid = valid_upper - valid_iqr / 2\n",
    "\n",
    "    # initialize outlier flag\n",
    "    outlier_arr = np.repeat(False,len(dates))\n",
    "\n",
    "    #######################\n",
    "    ## outlier detection ##\n",
    "    #######################\n",
    "\n",
    "    # calculate threshold\n",
    "    delta_threshold_upper = valid_upper + param_iqr * valid_iqr\n",
    "    delta_threshold_lower = valid_lower - param_iqr * valid_iqr\n",
    "\n",
    "    # outlier detection by threshold\n",
    "\n",
    "    deltas = []\n",
    "    is_outlier_threshold = []\n",
    "\n",
    "    for i in range(0,len(valid_idx)):\n",
    "\n",
    "        if valid_ndvi[i] > valid_upper[i]:\n",
    "\n",
    "                delta = valid_ndvi[i] - valid_upper[i]\n",
    "\n",
    "                if valid_ndvi[i] > delta_threshold_upper[i]:\n",
    "                    \n",
    "                    outlier = True\n",
    "                else:\n",
    "                    outlier = False\n",
    "        \n",
    "        elif (valid_ndvi[i] < valid_upper[i]) and (valid_ndvi[i] > valid_lower[i]):\n",
    "            \n",
    "            delta = valid_ndvi[i] - (valid_upper[i] - valid_iqr[i])\n",
    "            outlier = False\n",
    "\n",
    "        else:\n",
    "                delta = valid_ndvi[i] - valid_lower[i]\n",
    "\n",
    "                if valid_ndvi[i] < delta_threshold_lower[i]:\n",
    "                    \n",
    "                    outlier = True\n",
    "                else:\n",
    "                    outlier = False\n",
    "\n",
    "        deltas.append(delta)\n",
    "        is_outlier_threshold.append(outlier)\n",
    "        \n",
    "    is_outlier_threshold = np.array(is_outlier_threshold)\n",
    "    deltas = np.array(deltas)\n",
    "\n",
    "    # outlier detection by deltas neighbour\n",
    "    # the deltas are calculated based on the neaster bound\n",
    "\n",
    "    delta_delta_left = (deltas[1:] - deltas[:-1]) \n",
    "    delta_delta_right = (deltas[:-1] - deltas[1:]) \n",
    "\n",
    "    delta_delta_left = np.array(delta_delta_left)\n",
    "    delta_delta_right = np.array(delta_delta_right)\n",
    "\n",
    "\n",
    "    slope_is_outlier = np.logical_and(\n",
    "            \n",
    "            np.logical_or(delta_delta_left[1:] > np.quantile(delta_delta_left,upper_iqr), \n",
    "                        delta_delta_left[1:]  <  np.quantile(delta_delta_left,bottom_iqr)),\n",
    "\n",
    "            np.logical_or(delta_delta_right[:-1]  > np.quantile(delta_delta_right,upper_iqr), \n",
    "                        delta_delta_right[:-1]  < np.quantile(delta_delta_right,bottom_iqr))\n",
    "        )\n",
    "\n",
    "\n",
    "    # to be an outlier, a point must met both conditions\n",
    "    is_outlier = np.logical_and(is_outlier_threshold[1:-1],slope_is_outlier)\n",
    "\n",
    "    # write the outlier in the new data\n",
    "    outlier_arr[valid_idx[1:-1]] = is_outlier\n",
    "\n",
    "    # outlier detection first and last\n",
    "    if np.logical_and(\n",
    "        \n",
    "        np.logical_or(\n",
    "            delta_delta_right[0] >= np.quantile(delta_delta_right,upper_iqr), \n",
    "            delta_delta_right[0] <= np.quantile(delta_delta_right,bottom_iqr)\n",
    "            ),\n",
    "            \n",
    "            is_outlier_threshold[0]):\n",
    "\n",
    "        outlier_arr[valid_idx[0]] = True\n",
    "        ndvi_gapfilled[valid_idx[0]] = np.nan\n",
    "\n",
    "    if np.logical_and(\n",
    "                    \n",
    "            np.logical_or(\n",
    "                delta_delta_left[-1] >= np.quantile(delta_delta_left,upper_iqr), \n",
    "                delta_delta_left[-1] <= np.quantile(delta_delta_left,bottom_iqr)\n",
    "                ),\n",
    "                \n",
    "                is_outlier_threshold[-1]) == True:\n",
    "\n",
    "\n",
    "        outlier_arr[valid_idx[-1]] = True\n",
    "        ndvi_gapfilled[valid_idx[-1]] = np.nan\n",
    "\n",
    "    #######################\n",
    "    ## linear gapfilling ##\n",
    "    #######################\n",
    "\n",
    "    to_remove = valid_idx[1:-1][is_outlier == True]\n",
    "    ndvi_gapfilled[to_remove] = np.nan\n",
    "\n",
    "    valid_idx = np.where(np.isfinite(ndvi_gapfilled))\n",
    "    valid_idx = np.array(valid_idx[0])\n",
    "\n",
    "    distances = valid_idx[1:] - valid_idx[:-1]  \n",
    "\n",
    "    for i in range(0,len(valid_idx)-1):\n",
    "\n",
    "        idx_to_gapfill = range(valid_idx[i]+1,valid_idx[i+1])\n",
    "        idx_to_gapfill = np.array(idx_to_gapfill)\n",
    "\n",
    "        if len(idx_to_gapfill) != 0: # if len == 0 means 2 contigous obs data\n",
    "\n",
    "            multiplier = range(1,len(idx_to_gapfill)+1)\n",
    "            multiplier = np.array(multiplier)\n",
    "\n",
    "            # gapfill based on the median\n",
    "\n",
    "            delta_1 = ndvi_gapfilled[valid_idx[i]] - median_iqr[valid_idx[i]] \n",
    "            delta_2 = ndvi_gapfilled[valid_idx[i+1]] - median_iqr[valid_idx[i+1]] \n",
    "            \n",
    "            slope = (delta_2 - delta_1) / distances[i]\n",
    "\n",
    "            values = (median_iqr[idx_to_gapfill] + delta_1 + slope * multiplier ) \n",
    "\n",
    "\n",
    "            ndvi_gapfilled[idx_to_gapfill] = values\n",
    "\n",
    "\n",
    "    z_out[:, pixel] = ndvi_gapfilled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c0783cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    168\u001b[39m         values = (median_iqr[idx_to_gapfill] + delta_1 + slope * multiplier ) \n\u001b[32m    171\u001b[39m         ndvi_gapfilled[idx_to_gapfill] = values\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m z_out[:, pixel] = ndvi_gapfilled\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pixel % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mprint\u001b[39m(pixel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:2526\u001b[39m, in \u001b[36mArray.__setitem__\u001b[39m\u001b[34m(self, selection, value)\u001b[39m\n\u001b[32m   2524\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_orthogonal_selection(pure_selection, value, fields=fields)\n\u001b[32m   2525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2526\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_basic_selection(cast(BasicSelection, pure_selection), value, fields=fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/_compat.py:43\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     46\u001b[39m args_msg = [\n\u001b[32m     47\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:], strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     49\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/array.py:2746\u001b[39m, in \u001b[36mArray.set_basic_selection\u001b[39m\u001b[34m(self, selection, value, fields, prototype)\u001b[39m\n\u001b[32m   2744\u001b[39m     prototype = default_buffer_prototype()\n\u001b[32m   2745\u001b[39m indexer = BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m.shape, \u001b[38;5;28mself\u001b[39m.metadata.chunk_grid)\n\u001b[32m-> \u001b[39m\u001b[32m2746\u001b[39m sync(\u001b[38;5;28mself\u001b[39m._async_array._set_selection(indexer, value, fields=fields, prototype=prototype))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/site-packages/zarr/core/sync.py:156\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(coro, loop, timeout)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    154\u001b[39m future = asyncio.run_coroutine_threadsafe(_runner(coro), loop)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m finished, unfinished = wait([future], return_when=asyncio.ALL_COMPLETED, timeout=timeout)\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unfinished) > \u001b[32m0\u001b[39m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCoroutine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoro\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed to finish within \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/concurrent/futures/_base.py:305\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[32m    303\u001b[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m waiter.event.wait(timeout)\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m f._condition:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28mself\u001b[39m._cond.wait(timeout)\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ndvi/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         waiter.acquire()\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "z_out =  zarr.open(\"/home/francesco/data_scratch/swiss-ndvi-processing/lowland_broadleaf.zarr/ndvi\")\n",
    "\n",
    "for pixel in np.arange(0,len(sel)-1):\n",
    "\n",
    "    pixel_sel = sel[pixel]\n",
    "\n",
    "    time_serie = z[pixel_sel, ].astype(float)\n",
    "    time_serie /= 10000.0\n",
    "\n",
    "    # mask clouds\n",
    "    time_serie = np.where((time_serie > 1) | (time_serie < 0), np.nan, time_serie)\n",
    "\n",
    "    # proper sorting\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates_pd,\n",
    "        'ndvi': time_serie\n",
    "        })\n",
    "\n",
    "    df_sorted = df.sort_values(by='date')\n",
    "\n",
    "    dates_sorted = df_sorted['date'].values\n",
    "    ndvi_sorted = df_sorted['ndvi'].values\n",
    "\n",
    "    # initialize ndvi gapfilled\n",
    "    ndvi_gapfilled = np.copy(ndvi_sorted)\n",
    "\n",
    "\n",
    "    valid_idx = np.where(np.isfinite(ndvi_sorted))\n",
    "    valid_ndvi = ndvi_sorted[valid_idx]\n",
    "    valid_idx = np.array(valid_idx[0])\n",
    "    valid_upper = upper[valid_idx]\n",
    "    valid_lower = lower[valid_idx]\n",
    "\n",
    "    valid_iqr = valid_upper - valid_lower\n",
    "\n",
    "    median_valid = valid_upper - valid_iqr / 2\n",
    "\n",
    "    # initialize outlier flag\n",
    "    outlier_arr = np.repeat(False,len(dates))\n",
    "\n",
    "    #######################\n",
    "    ## outlier detection ##\n",
    "    #######################\n",
    "\n",
    "    # calculate threshold\n",
    "    delta_threshold_upper = valid_upper + param_iqr * valid_iqr\n",
    "    delta_threshold_lower = valid_lower - param_iqr * valid_iqr\n",
    "\n",
    "    # outlier detection by threshold\n",
    "\n",
    "    deltas = []\n",
    "    is_outlier_threshold = []\n",
    "\n",
    "    for i in range(0,len(valid_idx)):\n",
    "\n",
    "        if valid_ndvi[i] > valid_upper[i]:\n",
    "\n",
    "                delta = valid_ndvi[i] - valid_upper[i]\n",
    "\n",
    "                if valid_ndvi[i] > delta_threshold_upper[i]:\n",
    "                    \n",
    "                    outlier = True\n",
    "                else:\n",
    "                    outlier = False\n",
    "        \n",
    "        elif (valid_ndvi[i] < valid_upper[i]) and (valid_ndvi[i] > valid_lower[i]):\n",
    "            \n",
    "            delta = valid_ndvi[i] - (valid_upper[i] - valid_iqr[i])\n",
    "            outlier = False\n",
    "\n",
    "        else:\n",
    "                delta = valid_ndvi[i] - valid_lower[i]\n",
    "\n",
    "                if valid_ndvi[i] < delta_threshold_lower[i]:\n",
    "                    \n",
    "                    outlier = True\n",
    "                else:\n",
    "                    outlier = False\n",
    "\n",
    "        deltas.append(delta)\n",
    "        is_outlier_threshold.append(outlier)\n",
    "        \n",
    "    is_outlier_threshold = np.array(is_outlier_threshold)\n",
    "    deltas = np.array(deltas)\n",
    "\n",
    "    # outlier detection by deltas neighbour\n",
    "    # the deltas are calculated based on the neaster bound\n",
    "\n",
    "    delta_delta_left = (deltas[1:] - deltas[:-1]) \n",
    "    delta_delta_right = (deltas[:-1] - deltas[1:]) \n",
    "\n",
    "    delta_delta_left = np.array(delta_delta_left)\n",
    "    delta_delta_right = np.array(delta_delta_right)\n",
    "\n",
    "\n",
    "    slope_is_outlier = np.logical_and(\n",
    "            \n",
    "            np.logical_or(delta_delta_left[1:] > np.quantile(delta_delta_left,upper_iqr), \n",
    "                        delta_delta_left[1:]  <  np.quantile(delta_delta_left,bottom_iqr)),\n",
    "\n",
    "            np.logical_or(delta_delta_right[:-1]  > np.quantile(delta_delta_right,upper_iqr), \n",
    "                        delta_delta_right[:-1]  < np.quantile(delta_delta_right,bottom_iqr))\n",
    "        )\n",
    "\n",
    "\n",
    "    # to be an outlier, a point must met both conditions\n",
    "    is_outlier = np.logical_and(is_outlier_threshold[1:-1],slope_is_outlier)\n",
    "\n",
    "    # write the outlier in the new data\n",
    "    outlier_arr[valid_idx[1:-1]] = is_outlier\n",
    "\n",
    "    # outlier detection first and last\n",
    "    if np.logical_and(\n",
    "        \n",
    "        np.logical_or(\n",
    "            delta_delta_right[0] >= np.quantile(delta_delta_right,upper_iqr), \n",
    "            delta_delta_right[0] <= np.quantile(delta_delta_right,bottom_iqr)\n",
    "            ),\n",
    "            \n",
    "            is_outlier_threshold[0]):\n",
    "\n",
    "        outlier_arr[valid_idx[0]] = True\n",
    "        ndvi_gapfilled[valid_idx[0]] = np.nan\n",
    "\n",
    "    if np.logical_and(\n",
    "                    \n",
    "            np.logical_or(\n",
    "                delta_delta_left[-1] >= np.quantile(delta_delta_left,upper_iqr), \n",
    "                delta_delta_left[-1] <= np.quantile(delta_delta_left,bottom_iqr)\n",
    "                ),\n",
    "                \n",
    "                is_outlier_threshold[-1]) == True:\n",
    "\n",
    "\n",
    "        outlier_arr[valid_idx[-1]] = True\n",
    "        ndvi_gapfilled[valid_idx[-1]] = np.nan\n",
    "\n",
    "    #######################\n",
    "    ## linear gapfilling ##\n",
    "    #######################\n",
    "\n",
    "    to_remove = valid_idx[1:-1][is_outlier == True]\n",
    "    ndvi_gapfilled[to_remove] = np.nan\n",
    "\n",
    "    valid_idx = np.where(np.isfinite(ndvi_gapfilled))\n",
    "    valid_idx = np.array(valid_idx[0])\n",
    "\n",
    "    distances = valid_idx[1:] - valid_idx[:-1]  \n",
    "\n",
    "    for i in range(0,len(valid_idx)-1):\n",
    "\n",
    "        idx_to_gapfill = range(valid_idx[i]+1,valid_idx[i+1])\n",
    "        idx_to_gapfill = np.array(idx_to_gapfill)\n",
    "\n",
    "        if len(idx_to_gapfill) != 0: # if len == 0 means 2 contigous obs data\n",
    "\n",
    "            multiplier = range(1,len(idx_to_gapfill)+1)\n",
    "            multiplier = np.array(multiplier)\n",
    "\n",
    "            # gapfill based on the median\n",
    "\n",
    "            delta_1 = ndvi_gapfilled[valid_idx[i]] - median_iqr[valid_idx[i]] \n",
    "            delta_2 = ndvi_gapfilled[valid_idx[i+1]] - median_iqr[valid_idx[i+1]] \n",
    "            \n",
    "            slope = (delta_2 - delta_1) / distances[i]\n",
    "\n",
    "            values = (median_iqr[idx_to_gapfill] + delta_1 + slope * multiplier ) \n",
    "\n",
    "\n",
    "            ndvi_gapfilled[idx_to_gapfill] = values\n",
    "\n",
    "\n",
    "    z_out[:, pixel] = ndvi_gapfilled\n",
    "\n",
    "    if pixel % 100 == 0:\n",
    "        print(pixel)\n",
    "\n",
    "\n",
    "\n",
    "out_gif_gapfilled = \"ndvi_lowland_broadleaf_gapfilled.gif\"\n",
    "\n",
    "frames = []\n",
    "n_frames = min(100, z_out.shape[0])  # time dimension\n",
    "\n",
    "for t in range(n_frames):\n",
    "    # read NDVI for all masked pixels in window\n",
    "    values = z_out[t, :].astype(float)  # shape (len(sel),)\n",
    "\n",
    "    # reconstruct 2D window\n",
    "    window_arr = np.full(win_rows * win_cols, np.nan, dtype=float)\n",
    "    window_arr[is_masked] = values\n",
    "    window_arr = window_arr.reshape((win_rows, win_cols))\n",
    "\n",
    "    # plot frame\n",
    "    fig, ax = plt.subplots(figsize=(6, 6 * win_rows / win_cols))\n",
    "    im = ax.imshow(window_arr, origin='upper', extent=extent,\n",
    "                   vmin=0, vmax=1, cmap=\"RdYlGn\")\n",
    "    ax.set_title(f\"Gapfilled NDVI timestep {t}\")\n",
    "    ax.set_xlabel(\"EPSG:2056 (m)\")\n",
    "    ax.set_ylabel(\"EPSG:2056 (m)\")\n",
    "    plt.colorbar(im, ax=ax, label=\"NDVI\")\n",
    "\n",
    "    # convert to image\n",
    "    fig.canvas.draw()\n",
    "    buf = np.asarray(fig.canvas.buffer_rgba())\n",
    "    image = buf[:, :, :3].copy()\n",
    "    frames.append(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "# save GIF\n",
    "imageio.mimsave(out_gif_gapfilled, frames, fps=10)\n",
    "print(\"Saved GIF:\", out_gif_gapfilled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Array file:///home/francesco/data_scratch/swiss-ndvi-processing/lowland_broadleaf.zarr/ndvi shape=(1084, 2172) dtype=int16>\n"
     ]
    }
   ],
   "source": [
    "out_gif_gapfilled = \"ndvi_lowland_broadleaf_gapfilled.gif\"\n",
    "\n",
    "frames = []\n",
    "n_frames = min(100, z_out.shape[0])  # time dimension\n",
    "\n",
    "for t in range(n_frames):\n",
    "    # read NDVI for all masked pixels in window\n",
    "    values = z_out[t, :].astype(float)  # shape (len(sel),)\n",
    "\n",
    "    # reconstruct 2D window\n",
    "    window_arr = np.full(win_rows * win_cols, np.nan, dtype=float)\n",
    "    window_arr[is_masked] = values\n",
    "    window_arr = window_arr.reshape((win_rows, win_cols))\n",
    "\n",
    "    # plot frame\n",
    "    fig, ax = plt.subplots(figsize=(6, 6 * win_rows / win_cols))\n",
    "    im = ax.imshow(window_arr, origin='upper', extent=extent,\n",
    "                   vmin=0, vmax=1, cmap=\"RdYlGn\")\n",
    "    ax.set_title(f\"Gapfilled NDVI timestep {t}\")\n",
    "    ax.set_xlabel(\"EPSG:2056 (m)\")\n",
    "    ax.set_ylabel(\"EPSG:2056 (m)\")\n",
    "    plt.colorbar(im, ax=ax, label=\"NDVI\")\n",
    "\n",
    "    # convert to image\n",
    "    fig.canvas.draw()\n",
    "    buf = np.asarray(fig.canvas.buffer_rgba())\n",
    "    image = buf[:, :, :3].copy()\n",
    "    frames.append(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "# save GIF\n",
    "imageio.mimsave(out_gif_gapfilled, frames, fps=10)\n",
    "print(\"Saved GIF:\", out_gif_gapfilled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndvi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
